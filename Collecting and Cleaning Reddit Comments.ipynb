{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING THE DATA SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard Packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#Web Request Package\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How Do We Build a Data Set of Reddit Comments?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reddit, like many websites that produce large amounts of data that people may want to access, has what is called an API (Application Programming Interface).  Essentially this is a set of definitions, protocols, and tools that make data available in an accessible format for developers.  However, API's will typically have fairly strict limitations about the amount of data one can access, at least without paying a premium.\n",
    "\n",
    "Reddit's API is convenient in that it stores a lot of useful data and labeling relevant to each comment, user, etc. However, regular users of the API are limited to pulling 1000 comments at a time.  This in itself is not really an issue, but Reddit also limits users to only pulling the *most recent* 1000 comments.  This means we would have to wait for some indiscriminate amount of time between each pull, and given the volume of activity on these subreddits, it could be months or even years before we have a powerful dataset.  \n",
    "\n",
    "Luckily, there is an open-source alternative to Reddit's API, called **[Pushshift API](https://github.com/pushshift/api)**. In addition to providing useful extra features, the Pushshift API has two great advantages:\n",
    "\n",
    "- **We can specify a date and time that we want to start a pull from** (i.e.; pull the 1000 comments prior to time *t*). This allows us to create a loop backward over set intervals of time and pull as much distinct content as we want.\n",
    "\n",
    "\n",
    "- **The data is returned as a list of dictionaries**, which allows very easy conversion into Pandas.\n",
    "\n",
    "Let's access some Reddit comments and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The url given below calls for the most recent 1000 comments from threads on r/AskMen.\n",
    "url = \"https://api.pushshift.io/reddit/search/comment/?subreddit=askmen&sort=des&size=1000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = {'User-agent': 'eamonious'}\n",
    "res = requests.get(url, headers=headers)\n",
    "res.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 200 code indicates that we have successfully accessed the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "json = res.json()\n",
    "comments = pd.DataFrame(json['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the different data features available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'author_cakeday', 'author_flair_background_color',\n",
       "       'author_flair_css_class', 'author_flair_richtext',\n",
       "       'author_flair_template_id', 'author_flair_text',\n",
       "       'author_flair_text_color', 'author_flair_type', 'author_fullname',\n",
       "       'author_patreon_flair', 'body', 'created_utc', 'distinguished',\n",
       "       'gildings', 'id', 'link_id', 'no_follow', 'parent_id', 'permalink',\n",
       "       'retrieved_on', 'score', 'send_replies', 'stickied', 'subreddit',\n",
       "       'subreddit_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are interested in the following features: \n",
    "- **body**: raw text of the comment\n",
    "- **created_utc**: timestamp of the comment\n",
    "- **id**: comment unique id\n",
    "- **parent_id**: unique id of *parent* comment (or *thread id* for first tier comments that reply directly to the thread). Because of the way this category is formatted, we will be able to identify which comments are first tier comments.\n",
    "- **score**: how many upvotes the comment has\n",
    "- **subreddit**: subreddit that the comment was in.  this will be the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removes everything but the features we are interested in.\n",
    "comments = comments[['body','created_utc','id','parent_id','score','subreddit']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AskMen and AskWomen: Establishing a Proxy for Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be focusing on the subreddits **r/AskMen** and **r/AskWomen**.  \n",
    "\n",
    "The way these two subreddits work is people make threads in which they ask a question looking for answers from only male or only female redditors, respectively.  So, ***in each subreddit, we can expect the first-tier comments (replying directly to the thread) to be almost exclusively from men or women, respectively***: men answering questions in AskMen, and women answering questions in AskWomen. Thus, if we can grab first-tier comments only from each subreddit, we can get a large, balanced dataset of essentially gender-labeled Reddit comments, without any manual tagging.\n",
    "\n",
    "Accordingly, we want to collect only first-tier comments if possible, and exclude all lower-tier comment replies, which may be from either gender. ***We can filter for first-tier comments by using the 'parent_id' feature***.  First tier comments all show the thread id as the parent, which begins with 't3_'. Lower-tier comments show the id of the parent comment, which uses a different prefix.  All we need to do is exclude anything that doesn't have the 't3_' prefix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops all comments that are not in the first tier, i.e.; direct responses to the original post.\n",
    "comments['parent_id'] = comments['parent_id'].map(lambda x: x if 't3_' in x else 0)\n",
    "comments = comments[comments['parent_id']!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on experimentation, it looks like the percentage of every 1000 comments that are first tier comments is approximately the same in AskMen and AskWomen (~30-35%), so the classes should remain roughly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was 23 but I went with my ~29 year old cowor...</td>\n",
       "      <td>1545243578</td>\n",
       "      <td>ec4lbi4</td>\n",
       "      <td>t3_a7oy9v</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portland, OR.\\r\\r\\r\\n\\r\\r\\r\\nThe city itself i...</td>\n",
       "      <td>1545243546</td>\n",
       "      <td>ec4la0n</td>\n",
       "      <td>t3_a7mkui</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nope.    \"the cats goodbye\"      watch how a c...</td>\n",
       "      <td>1545243536</td>\n",
       "      <td>ec4l9lm</td>\n",
       "      <td>t3_a7fe60</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drunk as fuck me during an unintended one nigh...</td>\n",
       "      <td>1545243524</td>\n",
       "      <td>ec4l90i</td>\n",
       "      <td>t3_a79zu9</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There was this one time when I went over one o...</td>\n",
       "      <td>1545243449</td>\n",
       "      <td>ec4l5g6</td>\n",
       "      <td>t3_a7kmvc</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  created_utc       id  \\\n",
       "0  I was 23 but I went with my ~29 year old cowor...   1545243578  ec4lbi4   \n",
       "1  Portland, OR.\\r\\r\\r\\n\\r\\r\\r\\nThe city itself i...   1545243546  ec4la0n   \n",
       "2  nope.    \"the cats goodbye\"      watch how a c...   1545243536  ec4l9lm   \n",
       "3  Drunk as fuck me during an unintended one nigh...   1545243524  ec4l90i   \n",
       "4  There was this one time when I went over one o...   1545243449  ec4l5g6   \n",
       "\n",
       "   parent_id  score subreddit  \n",
       "0  t3_a7oy9v      1    AskMen  \n",
       "1  t3_a7mkui      1    AskMen  \n",
       "2  t3_a7fe60      1    AskMen  \n",
       "3  t3_a79zu9      1    AskMen  \n",
       "4  t3_a7kmvc      1    AskMen  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see we have the comment text, the timestamp (we'll discuss the format in a minute), the unique id, the parent id (only t3 means only first-tier!), the upvote count, and the subreddit.  This is our proof of concept.  Now let's go and get some data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling Comments from Pushshift.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted earlier, Reddit limits you to grabbing 1000 comments in a single call, and this rule extends to the Pushshift API as well.  To collect more than 1000 comments, and also to reflect a wider variety of timeframes than simply the last few days, we will use the feature in Pushshift that allows you to query based on a timestamp.  \n",
    "\n",
    "We can create a loop that repeatedly collects the 1000 first-tier comments from a subreddit prior to a specified date-time, starting at the present and moving backward at 12 day intervals. I chose 12 days because it will quickly give me a variety of times of year, times of month, days of week, etc., and it is a large enough gap that all comments should be new and my dataset will span at least a full year. \n",
    "\n",
    "The API uses the **epoch timestamp format**, a numerical representation.  12 days corresponds to 1036800 units in this format.  What I will do is use an initial timestamp from this week and then subtract 1036800 from it in each request, collecting comments further and further back in time and appending them until I have collected 40000+ first-tier comments from the AskMen subreddit.  I will then do the same thing for AskWomen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AskMen Data Grab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creates the initial dataframe \n",
    "#1000 most recent comments at present time (1545243580), filtered to first-tier only\n",
    "url = \"https://api.pushshift.io/reddit/search/comment/?subreddit=askmen&before=1545243580&sort=des&size=1000\"\n",
    "headers = {'User-agent': 'eamonious'}\n",
    "res = requests.get(url, headers=headers)\n",
    "json = res.json()\n",
    "commentsm = pd.DataFrame(json['data'])\n",
    "commentsm = commentsm[['body','created_utc','id','parent_id','score','subreddit']]\n",
    "#Filters for first-tier comments\n",
    "commentsm['parent_id'] = commentsm['parent_id'].map(lambda x: x if 't3_' in x else 0)\n",
    "commentsm = commentsm[commentsm['parent_id']!=0]\n",
    "#Gets rid of mod-removed comments\n",
    "commentsm = commentsm[commentsm['body']!='[removed]']\n",
    "\n",
    "#Loops backward over 12 day intervals, adding the 1000 most recent comments prior to each timepoint,\n",
    "#filtered to first-tier only\n",
    "for i in range(1,80):\n",
    "    url = \"https://api.pushshift.io/reddit/search/comment/?subreddit=askmen&before={}&sort=des&size=1000\".format(1545243580 - i*1036800)\n",
    "    headers = {'User-agent': 'eamonious'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    json = res.json()\n",
    "    commentbloc = pd.DataFrame(json['data'])\n",
    "    commentbloc = commentbloc[['body','created_utc','id','parent_id','score','subreddit']]\n",
    "    commentbloc['parent_id'] = commentbloc['parent_id'].map(lambda x: x if 't3_' in x else 0)\n",
    "    commentbloc = commentbloc[commentbloc['parent_id']!=0]\n",
    "    commentbloc = commentbloc[commentbloc['body']!='[removed]']\n",
    "    commentsm = pd.concat([commentsm, commentbloc], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43774"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commentsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AskWomen Data Grab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.pushshift.io/reddit/search/comment/?subreddit=askwomen&before=1545243580&sort=des&size=1000\"\n",
    "headers = {'User-agent': 'eamonious'}\n",
    "res = requests.get(url, headers=headers)\n",
    "json = res.json()\n",
    "commentsw = pd.DataFrame(json['data'])\n",
    "commentsw = commentsw[['body','created_utc','id','parent_id','score','subreddit']]\n",
    "commentsw['parent_id'] = commentsw['parent_id'].map(lambda x: x if 't3_' in x else 0)\n",
    "commentsw = commentsw[commentsw['parent_id']!=0]\n",
    "commentsw = commentsw[commentsw['body']!='[removed]']\n",
    "\n",
    "for i in range(1,80):\n",
    "    url = \"https://api.pushshift.io/reddit/search/comment/?subreddit=askwomen&before={}&sort=des&size=1000\".format(1545243580 - i*1036800)\n",
    "    headers = {'User-agent': 'eamonious'}\n",
    "    res = requests.get(url, headers=headers)\n",
    "    json = res.json()\n",
    "    commentbloc = pd.DataFrame(json['data'])\n",
    "    commentbloc = commentbloc[['body','created_utc','id','parent_id','score','subreddit']]\n",
    "    commentbloc['parent_id'] = commentbloc['parent_id'].map(lambda x: x if 't3_' in x else 0)\n",
    "    commentbloc = commentbloc[commentbloc['parent_id']!=0]\n",
    "    commentbloc = commentbloc[commentbloc['body']!='[removed]']\n",
    "    commentsw = pd.concat([commentsw, commentbloc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41555"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commentsw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classes are well balanced, both around 40k comments.  We have our data now.  But it needs some more work before we can analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning Away Mod Messages and Deleted Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to drop any rows with null values.  Second we want to make sure we don't have any duplicate comment IDs.  Because of the way we've collected, it's possible we could have some duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove rows with null values\n",
    "commentsm.dropna(inplace=True)\n",
    "commentsw.dropna(inplace=True)\n",
    "\n",
    "#Remove comments with the same ID\n",
    "commentsm.drop_duplicates('id',inplace=True)\n",
    "commentsw.drop_duplicates('id',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at value_counts in the 'body' category (comment text) to look at the most frequently appearing comments with the same text in each subreddit.  A number of these will be moderator boilerplate comments, which are specific to each subreddit.  We will want to remove these.  Also, when comments on reddit are deleted, they are typically replaced by text saying deleted or removed, we will want to get rid of anything like this as well.  \n",
    "\n",
    "We basically look at what comes up in the high frequency comments list, then filter out what we don't want based on identifying language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing deleted comments and moderator comments from AskMen\n",
    "commentsm = commentsm[commentsm['body']!='[deleted]']\n",
    "commentsm = commentsm[commentsm['body']!='\\\\[removed\\]']\n",
    "\n",
    "commentsm['body'] = commentsm['body'].map(lambda x: 0 if 'has been removed' in x else x)\n",
    "commentsm['body'] = commentsm['body'].map(lambda x: 0 if 'AskMen' in x else x)\n",
    "commentsm = commentsm[commentsm['body']!=0]\n",
    "\n",
    "\n",
    "#Removing deleted comments and moderator comments from AskWomen\n",
    "commentsw = commentsw[commentsw['body']!='[deleted]']\n",
    "\n",
    "commentsw['body'] = commentsw['body'].map(lambda x: 0 if 'has been removed' in x else x)\n",
    "commentsw['body'] = commentsw['body'].map(lambda x: 0 if 'emoved' in str(x)[0:10] else x)\n",
    "commentsw['body'] = commentsw['body'].map(lambda x: 0 if 'AskWomen' in str(x) else x)\n",
    "commentsw = commentsw[commentsw['body']!=0]\n",
    "\n",
    "commentsw = commentsw[commentsw['body']!='Please feel free to respond based on the genders that you find attractive. This question is not limited to women who date men.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33395, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38405, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commentsw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our classes are still reasonably well balanced.  We had a much larger number of duplicates (~7000) in the AskMen set, which basically suggests that AskMen is somewhat less active.  This isn't really surprising.  Now we will combine the AskMen and AskWomen comments into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was 23 but I went with my ~29 year old cowor...</td>\n",
       "      <td>1545243578</td>\n",
       "      <td>ec4lbi4</td>\n",
       "      <td>t3_a7oy9v</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portland, OR.\\r\\r\\r\\n\\r\\r\\r\\nThe city itself i...</td>\n",
       "      <td>1545243546</td>\n",
       "      <td>ec4la0n</td>\n",
       "      <td>t3_a7mkui</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nope.    \"the cats goodbye\"      watch how a c...</td>\n",
       "      <td>1545243536</td>\n",
       "      <td>ec4l9lm</td>\n",
       "      <td>t3_a7fe60</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drunk as fuck me during an unintended one nigh...</td>\n",
       "      <td>1545243524</td>\n",
       "      <td>ec4l90i</td>\n",
       "      <td>t3_a79zu9</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There was this one time when I went over one o...</td>\n",
       "      <td>1545243449</td>\n",
       "      <td>ec4l5g6</td>\n",
       "      <td>t3_a7kmvc</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  created_utc       id  \\\n",
       "0  I was 23 but I went with my ~29 year old cowor...   1545243578  ec4lbi4   \n",
       "1  Portland, OR.\\r\\r\\r\\n\\r\\r\\r\\nThe city itself i...   1545243546  ec4la0n   \n",
       "2  nope.    \"the cats goodbye\"      watch how a c...   1545243536  ec4l9lm   \n",
       "3  Drunk as fuck me during an unintended one nigh...   1545243524  ec4l90i   \n",
       "4  There was this one time when I went over one o...   1545243449  ec4l5g6   \n",
       "\n",
       "   parent_id  score subreddit  \n",
       "0  t3_a7oy9v      1    AskMen  \n",
       "1  t3_a7mkui      1    AskMen  \n",
       "2  t3_a7fe60      1    AskMen  \n",
       "3  t3_a79zu9      1    AskMen  \n",
       "4  t3_a7kmvc      1    AskMen  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = pd.concat([commentsm, commentsw])\n",
    "comments = comments.reset_index(drop=True)\n",
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that comment with '\\r\\r\\r\\r\\n...' Those are line breaks, when people put paragraphs in their comments. Let's check and see how many comments have these things in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23261"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments['body'].map(lambda x: x if '\\r' in x else 0).unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So 23000+ comments have a \\r combo somewhere! This will interfere with our attempt to calculate word length, and may affect our vectorizations and predictions too.  If we look through the data further, there are also a large number of multiple spaces in some comments.  When we go to calculate word length, we're going to want to use the space character as a splitter.  So we need to reduce these to single spaces, or we'll get a bunch of empty spaces counted as words.  \n",
    "\n",
    "So we want to remove all the \\r\\n combos, and all the multi-spaces, and replace them with one empty space.  We can make this type of specific text substitution with **regular expressions** (regex for short)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Regex\n",
    "import re\n",
    "\n",
    "#This function selects any consecutive combination of \\r's and \\n's in a bloc of text, \n",
    "#and replaces that selection with a single space.\n",
    "def replace_linebreaks_w_space(x):\n",
    "    return re.sub('([\\r\\n]+)',' ',x) \n",
    "\n",
    "#This function selects any stretch of two or more consecutive spaces in a bloc of text,\n",
    "#and replaces that selection with a single space.\n",
    "def replace_multispace_w_space(x):\n",
    "    return re.sub('([ ]{2,})',' ',x)\n",
    "\n",
    "#Here we take every comment and apply the two functions to it.\n",
    "comments['body'] = comments['body'].map(replace_linebreaks_w_space)\n",
    "comments['body'] = comments['body'].map(replace_multispace_w_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOW we can make a column with a proper word length count for each comment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strip away any spaces at the beginning or end of each comment, splits the comment into a list of words, \n",
    "#and returns the length of that list (i.e.; the number of words in the comment)\n",
    "comments['word_length'] = comments['body'].map(lambda x: len(x.strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>score</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>word_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I was 23 but I went with my ~29 year old cowor...</td>\n",
       "      <td>1545243578</td>\n",
       "      <td>ec4lbi4</td>\n",
       "      <td>t3_a7oy9v</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portland, OR. The city itself is now unafforda...</td>\n",
       "      <td>1545243546</td>\n",
       "      <td>ec4la0n</td>\n",
       "      <td>t3_a7mkui</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nope. \"the cats goodbye\" watch how a cat says ...</td>\n",
       "      <td>1545243536</td>\n",
       "      <td>ec4l9lm</td>\n",
       "      <td>t3_a7fe60</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Drunk as fuck me during an unintended one nigh...</td>\n",
       "      <td>1545243524</td>\n",
       "      <td>ec4l90i</td>\n",
       "      <td>t3_a79zu9</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There was this one time when I went over one o...</td>\n",
       "      <td>1545243449</td>\n",
       "      <td>ec4l5g6</td>\n",
       "      <td>t3_a7kmvc</td>\n",
       "      <td>1</td>\n",
       "      <td>AskMen</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  created_utc       id  \\\n",
       "0  I was 23 but I went with my ~29 year old cowor...   1545243578  ec4lbi4   \n",
       "1  Portland, OR. The city itself is now unafforda...   1545243546  ec4la0n   \n",
       "2  nope. \"the cats goodbye\" watch how a cat says ...   1545243536  ec4l9lm   \n",
       "3  Drunk as fuck me during an unintended one nigh...   1545243524  ec4l90i   \n",
       "4  There was this one time when I went over one o...   1545243449  ec4l5g6   \n",
       "\n",
       "   parent_id  score subreddit  word_length  \n",
       "0  t3_a7oy9v      1    AskMen           23  \n",
       "1  t3_a7mkui      1    AskMen           36  \n",
       "2  t3_a7fe60      1    AskMen           28  \n",
       "3  t3_a79zu9      1    AskMen           16  \n",
       "4  t3_a7kmvc      1    AskMen          192  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have accurate word length data. PS. Notice that the \\r\\r\\r\\n is gone from that comment!\n",
    "\n",
    "The last thing we're going to do is ***remove all comments that are 3 words and shorter***, as it's difficult, and for the most part just unreasonable, to guess anything from comments this short.  We want to focus on accurately predicting comments that have some content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67354"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments = comments[comments['word_length']>=4]\n",
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AskWomen    36335\n",
       "AskMen      31019\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our cleaned dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv('./csvs/comments_final.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
